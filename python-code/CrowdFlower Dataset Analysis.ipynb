{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "##set up the environment\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "#import regex\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load Data\n",
    "labeledData = pd.read_csv('../CrowdFlowerDataset/labeled_data.csv')\n",
    "labeledData.head()\n",
    "sarcasmData = pd.read_csv('../SarcasmDataset/sarcasm_v2.csv')\n",
    "sarcasmData.head()\n",
    "taggedData = pd.read_csv('tagged_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeledData[\"hs_score\"] = labeledData[\"hate_speech\"]/labeledData[\"count\"]\n",
    "labeledData[\"ol_score\"] = labeledData[\"offensive_language\"]/labeledData[\"count\"]\n",
    "labeledData[\"n_score\"] = labeledData[\"neither\"]/labeledData[\"count\"]\n",
    "sarcasmData[\"class\"] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(896, 5)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeledData[labeledData[\"hate_speech\"]>0].head()\n",
    "taggedData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30371"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concat datasets\n",
    "X_data = pd.concat([labeledData[\"tweet\"],sarcasmData[\"Response Text\"],taggedData['tweet_content']])\n",
    "y_data = pd.concat([labeledData[\"class\"],sarcasmData[\"class\"],taggedData['class']])\n",
    "X_data.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing    \n",
    "X_data = X_data.str.lower()  #Convert to lower case\n",
    "X_data = X_data.apply((lambda x: re.sub('[!]+ rt ',' RT ', x))) \n",
    "X_data = X_data.apply((lambda x: re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','URL',x)))     #Convert www.* or https?://* to URL\n",
    "X_data = X_data.apply((lambda x: re.sub('@[^\\s]+','AT_USER',x)))      #Convert @username to AT_USER\n",
    "X_data = X_data.apply((lambda x: re.sub('[\\s]+', ' ', x)))          #Remove additional white spaces\n",
    "X_data = X_data.apply((lambda x: re.sub(r'#([^\\s]+)', r'\\1', x)))   #Replace #word with word\n",
    "X_data = X_data.str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30371,)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "train_tfidf.shape\n",
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/stochastic_gradient.py:84: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.90491241933359678"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train a SGD classifier\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_data)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X = train_tfidf\n",
    "y = y_data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "estimator = SGDClassifier(loss=\"hinge\", penalty=\"l2\")\n",
    "estimator.fit(X_train, y_train)\n",
    "prediction = estimator.predict(X_test)\n",
    "accuracy_score(y_test,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=5, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
       "       shuffle=True, tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#completely fit\n",
    "estimator.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(estimator, open(\"model/sgdClassifier.p\",\"wb\"))\n",
    "pickle.dump(count_vect, open(\"model/hurtVectorizer.p\",\"wb\"))\n",
    "pickle.dump(tfidf_transformer, open(\"model/hurtVectorizerTfIdf.p\",\"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train_counts = count_vect.transform([\"hola\"])\n",
    "train_tfidf = tfidf_transformer.transform(X_train_counts)\n",
    "train_tfidf\n",
    "estimator.predict(train_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "for x in [\"hola,como,estas\".split(',')]:\n",
    "    print(x.__class__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inplace_change(filename, old_string, new_string):\n",
    "    # Safely read the input filename using 'with'\n",
    "    with open(filename) as f:\n",
    "        s = f.read()\n",
    "        if old_string not in s:\n",
    "            return\n",
    "\n",
    "    # Safely write the changed content, if found in the file\n",
    "    with open(filename, 'w') as f:\n",
    "        s = s.replace(old_string, new_string)\n",
    "        f.write(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "template = \"/home/alejandra/Documents/ELK_Twitter/ELK_twitter/src/twitter-pipeline/config/user_twitter_pipeline_template.conf\"\n",
    "newFile = \"/home/alejandra/Documents/ELK_Twitter/ELK_twitter/src/twitter-pipeline/config/user_twitter_pipeline1.conf\"\n",
    "copyfile(template,newFile)\n",
    "inplace_change(newFile,\"<user_list_to_insert>\",\"\\\"\" + \"\\\",\\\"\".join(['hola','como','estas']) + \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1', '2', '3']"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"]\n",
    "a[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
